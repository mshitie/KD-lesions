{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Temperature_10.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mshitie/MS_KD/blob/main/temperature/Temperature_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwJzQrr6u_s9",
        "outputId": "46f2e681-599f-4aed-db71-0d2481a2fb99"
      },
      "source": [
        "\n",
        "!pip install rarfile\n",
        "\n",
        "from google.colab import drive\n",
        "import rarfile\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the .rar file in Google Drive\n",
        "rar_path = '/content/drive/MyDrive/computer_vision/main_data_croped.rar'\n",
        "\n",
        "# Destination folder to extract the contents\n",
        "destination_folder = '/content'\n",
        "\n",
        "# Create the destination folder if it doesn't exist\n",
        "if not os.path.exists(destination_folder):\n",
        "    os.makedirs(destination_folder)\n",
        "\n",
        "# Extract the .rar file\n",
        "with rarfile.RarFile(rar_path, 'r') as rar_ref:\n",
        "    rar_ref.extractall(destination_folder)\n",
        "\n",
        "print(\"Extraction completed.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import shutil\n",
        "\n",
        "def partition_images(directory, csv_file, output_folder):\n",
        "    image_files = []\n",
        "    folder_counts = {}  # Dictionary to store the count of images moved to each folder\n",
        "\n",
        "    # Read the CSV file\n",
        "    with open(csv_file, 'r') as file:\n",
        "        reader = csv.reader(file)\n",
        "        header = next(reader, None)  # Skip the header row if it exists\n",
        "\n",
        "        # Iterate over the rows in the CSV file\n",
        "        for row in reader:\n",
        "            image_file = row[0]  # Assuming the image file names are in the first column\n",
        "            label = row[1]  # Assuming the labels are in the second column\n",
        "            image_files.append((image_file, label))\n",
        "\n",
        "    # Create directories for each label\n",
        "    labels = set(label for _, label in image_files)\n",
        "    for label in labels:\n",
        "        label_dir = os.path.join(output_folder, label)\n",
        "        os.makedirs(label_dir, exist_ok=True)\n",
        "        folder_counts[label] = 0  # Initialize the count to 0\n",
        "\n",
        "    # Move the image files to separate label directories\n",
        "    for image_file, label in image_files:\n",
        "        source_path = os.path.join(directory, image_file + \".jpg\")  # Assuming the file extension is '.jpg'\n",
        "        destination_path = os.path.join(output_folder, label, image_file + \".jpg\")\n",
        "\n",
        "        if os.path.exists(source_path):\n",
        "            print(f\"Moving {source_path} to {destination_path}\")\n",
        "            shutil.move(source_path, destination_path)\n",
        "            folder_counts[label] += 1  # Increment the count for the corresponding folder\n",
        "\n",
        "        else:\n",
        "            print(f\"File not found: {source_path}\")\n",
        "\n",
        "    # Print the counts for each folder\n",
        "    print(\"\\nNumber of images moved in each folder:\")\n",
        "    for label, count in folder_counts.items():\n",
        "        print(f\"{label}: {count}\")\n",
        "\n",
        "# Directory path where the images and CSV file are located\n",
        "directory_path = '/content/main_data_croped/'\n",
        "csv_file_path = '/content/drive/MyDrive/computer_vision/tfti2.csv'\n",
        "output_folder = \"/content/main_data_croped2/\"\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Call the function to partition the images based on the labels\n",
        "partition_images(directory_path, csv_file_path, output_folder)"
      ],
      "metadata": {
        "id": "H_3KKedEaBkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nQN1RamvUkt"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import scipy\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n",
        "\n",
        "import time\n",
        "import timeit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5LafAravWx_"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "from keras.models import Model\n",
        "from keras.layers import Lambda, concatenate\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import GlobalAveragePooling2D , Conv2D , MaxPooling2D\n",
        "from keras.layers import  Dropout , BatchNormalization , Dense\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from keras.callbacks import Callback , ReduceLROnPlateau , ModelCheckpoint\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "from keras.losses import categorical_crossentropy as logloss\n",
        "from keras.metrics import categorical_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "train_dir = '/content/main_data_croped2'\n",
        "\n",
        "# Load train images\n",
        "tf_train = []\n",
        "for filename in os.listdir(os.path.join(train_dir, 'TF')):\n",
        "    img = Image.open(os.path.join(train_dir, 'TF', filename)).convert('RGB')\n",
        "    img = img.resize((224, 224))  # Resize if necessary\n",
        "    img_array = np.array(img)\n",
        "    tf_train.append(img_array)\n",
        "tf_train = np.array(tf_train)\n",
        "\n",
        "it_train = []\n",
        "for filename in os.listdir(os.path.join(train_dir, 'TI')):\n",
        "    img = Image.open(os.path.join(train_dir, 'TI', filename)).convert('RGB')\n",
        "    img = img.resize((224, 224))  # Resize if necessary\n",
        "    img_array = np.array(img)\n",
        "    it_train.append(img_array)\n",
        "it_train = np.array(it_train)\n",
        "\n",
        "normal_train = []\n",
        "for filename in os.listdir(os.path.join(train_dir, 'normal')):\n",
        "    img = Image.open(os.path.join(train_dir, 'normal', filename)).convert('RGB')\n",
        "    img = img.resize((224, 224))  # Resize if necessary\n",
        "    img_array = np.array(img)\n",
        "    normal_train.append(img_array)\n",
        "normal_train = np.array(normal_train)\n",
        "\n",
        "print('Done Loaded :)')\n",
        "\n",
        "# Shape of our dataset\n",
        "print(f'TF Train:', tf_train.shape)\n",
        "print(f'TI Train:', it_train.shape)\n",
        "print(f'Normal Train:', normal_train.shape)\n",
        "\n",
        "tf_train_label = np.zeros(len(tf_train), dtype=float)\n",
        "it_train_label = np.ones(len(it_train), dtype=float)\n",
        "normal_train_label = np.full(len(normal_train), 2, dtype=float)\n",
        "\n",
        "X_train = np.concatenate((tf_train, it_train, normal_train), axis=0)\n",
        "Y_train = np.concatenate((tf_train_label, it_train_label, normal_train_label), axis=0)\n",
        "\n",
        "s = np.arange(X_train.shape[0])\n",
        "np.random.shuffle(s)\n",
        "X_train = X_train[s]\n",
        "Y_train = Y_train[s]\n",
        "\n",
        "Y_train = to_categorical(Y_train, num_classes=3)\n",
        "\n",
        "print(f'X train shape:', X_train.shape)\n",
        "print(f'Y train shape:', Y_train.shape)\n",
        "\n",
        "# Split the data into training, validation, and testing sets\n",
        "x_train, x_temp, y_train, y_temp = train_test_split(X_train, Y_train, test_size=0.2, random_state=10)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=10)\n",
        "\n",
        "print(f'x train shape:', x_train.shape)\n",
        "print(f'x test shape:', x_test.shape)\n",
        "print(f'x val shape:', x_val.shape)\n",
        "print(f'y train shape:', y_train.shape)\n",
        "print(f'y test shape:', y_test.shape)\n",
        "print(f'y val shape:', y_val.shape)"
      ],
      "metadata": {
        "id": "pf3lfJMzaQmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3O5-mfAvpmL",
        "outputId": "456ecaf3-0f29-4cc1-a54b-88e9463f2a22"
      },
      "source": [
        "# Teacher model with ResNet50\n",
        "def build_model(backbone , lr = 1e-4):\n",
        "  model = Sequential()\n",
        "  model.add(backbone)\n",
        "  model.add(layers.GlobalAveragePooling2D())\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Dense(3 , activation='softmax'))\n",
        "\n",
        "  model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=Adam(learning_rate=1e-4),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "  return model\n",
        "\n",
        "resnet = ResNet50(\n",
        "    weights = 'imagenet',\n",
        "    include_top = False,\n",
        "    input_shape = (224 , 224 , 3)\n",
        ")\n",
        "# call the model\n",
        "model = build_model(resnet , lr = 1e-4)\n",
        "model.build((None, 224, 224, 3))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "module_wrapper_2 (ModuleWrap (None, 7, 7, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 2048)              8192      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 4098      \n",
            "=================================================================\n",
            "Total params: 23,600,002\n",
            "Trainable params: 23,542,786\n",
            "Non-trainable params: 57,216\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NzK9jN7i6yP"
      },
      "source": [
        "learn_control = ReduceLROnPlateau(monitor='val_acc', patience=5,verbose=1,factor=0.2, min_lr=1e-4)\n",
        "filepath=\"ResNet50weights.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVroJarTwWl6",
        "outputId": "a4e3cf85-6f56-428a-ce69-3422b82a36a1"
      },
      "source": [
        "# Training the teacher model with Resnet50\n",
        "# Train the teacher model as usual\n",
        "# Configuration\n",
        "import time\n",
        "epochs = 10\n",
        "batch_size = 64\n",
        "\n",
        "# Calculate the starting time\n",
        "start_time = time.time()\n",
        "\n",
        "teacher_his = model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            verbose=1,\n",
        "            validation_data=(x_val, y_val),\n",
        "            callbacks=[learn_control, checkpoint])\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"--- Time taken to train : %s seconds ---\" % ((end_time - start_time)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "88/88 [==============================] - 61s 637ms/step - loss: 0.3081 - accuracy: 0.8843 - val_loss: 0.2629 - val_accuracy: 0.8729\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 2/10\n",
            "88/88 [==============================] - 57s 643ms/step - loss: 0.0644 - accuracy: 0.9741 - val_loss: 0.1101 - val_accuracy: 0.9650\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 3/10\n",
            "88/88 [==============================] - 58s 655ms/step - loss: 0.0294 - accuracy: 0.9903 - val_loss: 0.1530 - val_accuracy: 0.9393\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 4/10\n",
            "88/88 [==============================] - 58s 663ms/step - loss: 0.0159 - accuracy: 0.9940 - val_loss: 0.1766 - val_accuracy: 0.9593\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 5/10\n",
            "88/88 [==============================] - 58s 663ms/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 0.1599 - val_accuracy: 0.9543\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 6/10\n",
            "88/88 [==============================] - 58s 665ms/step - loss: 0.0454 - accuracy: 0.9843 - val_loss: 0.1656 - val_accuracy: 0.9443\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 7/10\n",
            "88/88 [==============================] - 58s 665ms/step - loss: 0.0139 - accuracy: 0.9945 - val_loss: 0.1658 - val_accuracy: 0.9571\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 8/10\n",
            "88/88 [==============================] - 58s 664ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.1792 - val_accuracy: 0.9593\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 9/10\n",
            "88/88 [==============================] - 59s 675ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.1863 - val_accuracy: 0.9621\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 10/10\n",
            "88/88 [==============================] - 58s 665ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.3269 - val_accuracy: 0.9536\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "--- Time taken to train : 627.1994976997375 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWGepXgSjynR",
        "outputId": "9102ca51-57f6-4d1e-a1a7-63be44acf7c7"
      },
      "source": [
        "model.save_weights(\"ResNet50_model.h5\") #using h5 extension\n",
        "print(\"model saved!!!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model saved!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9C50c_0zzjJ",
        "outputId": "ee67d214-c61a-441e-bbd6-22fee4610072"
      },
      "source": [
        "Y_val_pred = model.predict(x_val)\n",
        "print(f'The Teacher model Accuracy on the Validation Set:',accuracy_score(np.argmax(y_val, axis=1), np.argmax(Y_val_pred, axis=1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Teacher model Accuracy on the Validation Set: 0.9535714285714286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ybwvuF9z0Nf",
        "outputId": "9c546ea6-ce30-4710-b4eb-afcddfe2fc00"
      },
      "source": [
        "#Now let's check my Y_test values\n",
        "print(f'My Y_test values are:\\n' ,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My Y_test values are:\n",
            " [[1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc8YoU-Hz6D3",
        "outputId": "9c90ac9c-97b7-4810-c427-f2e8ef5026db"
      },
      "source": [
        "#Now let's check my predcited values from x_test dataset\n",
        "# And calculate the y_pred with time\n",
        "import timeit\n",
        "\n",
        "start = timeit.default_timer()\n",
        "#Your statements here\n",
        "y_pred = model.predict(x_test)\n",
        "print(f'My predicted Y_test values are:\\n' ,y_pred)\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "print('\\nTime: ',stop - start,'sec')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My predicted Y_test values are:\n",
            " [[9.9991727e-01 8.2722137e-05]\n",
            " [2.0833357e-12 1.0000000e+00]\n",
            " [9.9999917e-01 8.7726909e-07]\n",
            " ...\n",
            " [9.9992621e-01 7.3832161e-05]\n",
            " [7.8759923e-09 1.0000000e+00]\n",
            " [9.9999154e-01 8.4888525e-06]]\n",
            "\n",
            "Time:  8.099131862999911 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDvD1tKvmzup",
        "outputId": "f6e4909e-6753-4937-fda7-866857567a93"
      },
      "source": [
        "start = timeit.default_timer()\n",
        "#Your statements here\n",
        "\n",
        "#Now let's check the accuracy between the original & predicted (Y_test , y_pred)\n",
        "print(f'My accuracy on Teacher model with ResNet50 on the Test set is:',accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)))\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "print('\\nTime: ',stop - start,'sec')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My accuracy on Teacher model with ResNet50 on the Test set is: 0.991\n",
            "\n",
            "Time:  0.0009553229997436574 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy97eTzunYLp",
        "outputId": "ff6c071d-53df-479f-8be2-662cac062a23"
      },
      "source": [
        "# Classification_report\n",
        "print(f'Classification Report of Resnet50:\\n',classification_report(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report of Resnet50:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1500\n",
            "           1       0.98      1.00      0.99      1500\n",
            "\n",
            "    accuracy                           0.99      3000\n",
            "   macro avg       0.99      0.99      0.99      3000\n",
            "weighted avg       0.99      0.99      0.99      3000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gedmLVmMrsWF"
      },
      "source": [
        "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from numpy import interp\n",
        "from itertools import cycle\n",
        "\n",
        "num_of_classes = y_train.shape[1]\n",
        "print(f'Auc Curve on Validation:\\n')\n",
        "\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(num_of_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_val[:, i], Y_val_pred[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_val.ravel(), Y_val_pred.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "\n",
        "lw = 3\n",
        "# Plot all ROC curves\n",
        "\n",
        "colors = cycle(['blue', 'orange', 'cornflowerblue'])\n",
        "for i, color in zip(range(num_of_classes), colors):\n",
        "    plt.plot(fpr[i],tpr[i], color=color, lw=lw,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrqGDS-WpM0c"
      },
      "source": [
        "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from numpy import interp\n",
        "from itertools import cycle\n",
        "\n",
        "num_of_classes = y_train.shape[1]\n",
        "print(f'Auc Curve on Test set:\\n')\n",
        "\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(num_of_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(Y_test[:, i], y_pred[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_test.ravel(), y_pred.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "\n",
        "lw = 3\n",
        "# Plot all ROC curves\n",
        "\n",
        "colors = cycle(['blue', 'orange', 'cornflowerblue'])\n",
        "for i, color in zip(range(num_of_classes), colors):\n",
        "    plt.plot(fpr[i],tpr[i], color=color, lw=lw,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1EPv8aFnYos"
      },
      "source": [
        "**Student Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgVqzo_jvs9x",
        "outputId": "d2177d8b-3730-46d2-c0c6-a43eda6fb913"
      },
      "source": [
        "# Define the student model\n",
        "# Student model that is stand-alone. We will evaluate its accuracy compared to a teacher trained student model\n",
        "# Hyperparameters\n",
        "input_shape = (224, 224, 3) # Input shape of each image\n",
        "nb_classes = 3\n",
        "\n",
        "customstudent = Sequential()\n",
        "customstudent.add(Conv2D(128, kernel_size=(3, 3),activation='relu', input_shape=input_shape))\n",
        "customstudent.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "customstudent.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "customstudent.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "customstudent.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "customstudent.add(Dropout(0.25)) # For reguralization\n",
        "\n",
        "customstudent.add(layers.Flatten())\n",
        "\n",
        "customstudent.add(layers.Dense(nb_classes))\n",
        "customstudent.add(layers.Activation('softmax')) # Note that we add a normal softmax layer to begin with\n",
        "\n",
        "\n",
        "customstudent.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adadelta',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(customstudent.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 222, 222, 128)     3584      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 111, 111, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 109, 109, 64)      73792     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 52, 52, 32)        18464     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 52, 52, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 86528)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 173058    \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 268,898\n",
            "Trainable params: 268,898\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH990HN_0Ovn"
      },
      "source": [
        "# Define a new model that outputs only teacher logits\n",
        "# Raise the temperature of teacher model and gather the soft targets\n",
        "\n",
        "# Collect the logits from the previous layer output and store it in a different model\n",
        "teacher_WO_Softmax = Model(model.input, model.get_layer('dense_2').output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKo9WI4Y0WWh"
      },
      "source": [
        "# Define a manual softmax function\n",
        "def softmax(x):\n",
        "    return np.exp(x)/(np.exp(x).sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xVEZmwE8Gy1"
      },
      "source": [
        "# Temperature = 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0xHXnJD0YXu",
        "outputId": "ea34e351-6318-4889-826c-55d0a46957dd"
      },
      "source": [
        "# Prepare the soft targets and the target data for student to be trained upon\n",
        "# From our temperature experiment we get temp = 10 is gave is best results\n",
        "temp = 10\n",
        "# This model directly gives the logits ( see the teacher_WO_softmax model above)\n",
        "teacher_train_logits = teacher_WO_Softmax.predict(x_train)\n",
        "teacher_test_logits = teacher_WO_Softmax.predict(x_val)\n",
        "\n",
        "# Perform a manual softmax at raised temperature\n",
        "train_logits_T = teacher_train_logits/ temp # temp = 10\n",
        "test_logits_T = teacher_test_logits / temp\n",
        "\n",
        "Y_train_soft = softmax(train_logits_T)\n",
        "Y_test_soft = softmax(test_logits_T)\n",
        "\n",
        "# Concatenate\n",
        "Y_train_new = np.concatenate([y_train, Y_train_soft], axis=1)\n",
        "Y_test_new =  np.concatenate([y_val, Y_test_soft], axis =1)\n",
        "\n",
        "#Print the Shape\n",
        "print(train_logits_T.shape)\n",
        "print(test_logits_T.shape)\n",
        "print(Y_train_new.shape)\n",
        "print(Y_test_new.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5596, 2)\n",
            "(1400, 2)\n",
            "(5596, 4)\n",
            "(1400, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UEnZ3Ya0bko",
        "outputId": "b6da1081-3867-4233-f149-c8b0da01141f"
      },
      "source": [
        "# Prepare the student model that outputs probabilities with and without temperature\n",
        "# Remove the softmax layer from the student network\n",
        "temp = 10\n",
        "customstudent.layers.pop()\n",
        "\n",
        "# Now collect the logits from the last layer\n",
        "# This is going to be a tensor. And hence it needs to pass through a Activation layer\n",
        "logits = customstudent.layers[-1].output\n",
        "probs = layers.Activation('softmax')(logits)\n",
        "\n",
        "\n",
        "# softed probabilities at raised temperature\n",
        "logits_T = Lambda(lambda x: x / temp)(logits)\n",
        "probs_T = layers.Activation('softmax')(logits_T)\n",
        "\n",
        "output = concatenate([probs, probs_T])\n",
        "\n",
        "# This is our new student model\n",
        "customstudent = Model(customstudent.input, output)\n",
        "\n",
        "customstudent.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "conv2d_input (InputLayer)       [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 222, 222, 128 3584        conv2d_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 111, 111, 128 0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 109, 109, 64) 73792       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 54, 54, 64)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 52, 52, 32)   18464       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 52, 52, 32)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 86528)        0           dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            173058      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 2)            0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 2)            0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 2)            0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 2)            0           lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 4)            0           activation_1[0][0]               \n",
            "                                                                 activation_2[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 268,898\n",
            "Trainable params: 268,898\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brOe8JSp0gA_"
      },
      "source": [
        "# Declare knowledge distillation loss function\n",
        "# This will be a teacher trained student model.\n",
        "# This uses a knowledge distillation loss function\n",
        "# Declare knowledge distillation loss\n",
        "def knowledge_distillation_loss(y_true, y_pred, alpha):\n",
        "\n",
        "    # Extract the one-hot encoded values and the softs separately so that we can create two objective functions\n",
        "    y_true, y_true_softs = y_true[: , :nb_classes], y_true[: , nb_classes:]\n",
        "\n",
        "    y_pred, y_pred_softs = y_pred[: , :nb_classes], y_pred[: , nb_classes:]\n",
        "\n",
        "    loss = alpha*logloss(y_true,y_pred) + (1-alpha)*logloss(y_true_softs, y_pred_softs)\n",
        "\n",
        "    return loss\n",
        "\n",
        "# For testing use regular output probabilities - without temperature\n",
        "def acc(y_true, y_pred):\n",
        "    y_true = y_true[:, :nb_classes]\n",
        "    y_pred = y_pred[:, :nb_classes]\n",
        "    return categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "customstudent.compile(\n",
        "    #optimizer=optimizers.SGD(lr=1e-1, momentum=0.9, nesterov=True),\n",
        "    optimizer='adadelta',\n",
        "    loss=lambda y_true, y_pred: knowledge_distillation_loss(y_true, y_pred, 0.1),\n",
        "    #loss='categorical_crossentropy',\n",
        "    metrics=[acc]\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XLkOCYK0lBz",
        "outputId": "e709ca8a-7801-41cc-a4b1-fac11b0af9de"
      },
      "source": [
        "# Train the student model\n",
        "epochs = 20\n",
        "batch_size = 64\n",
        "customstudent_student_his = customstudent.fit(x_train, Y_train_new,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_val, Y_test_new))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "88/88 [==============================] - 16s 184ms/step - loss: 0.0441 - acc: 0.8710 - val_loss: 0.0442 - val_acc: 0.8750\n",
            "Epoch 2/20\n",
            "88/88 [==============================] - 16s 184ms/step - loss: 0.0439 - acc: 0.8733 - val_loss: 0.0448 - val_acc: 0.8671\n",
            "Epoch 3/20\n",
            "88/88 [==============================] - 16s 185ms/step - loss: 0.0434 - acc: 0.8788 - val_loss: 0.0442 - val_acc: 0.8750\n",
            "Epoch 4/20\n",
            "88/88 [==============================] - 16s 185ms/step - loss: 0.0439 - acc: 0.8740 - val_loss: 0.0443 - val_acc: 0.8721\n",
            "Epoch 5/20\n",
            "88/88 [==============================] - 16s 185ms/step - loss: 0.0437 - acc: 0.8763 - val_loss: 0.0442 - val_acc: 0.8750\n",
            "Epoch 6/20\n",
            "88/88 [==============================] - 16s 186ms/step - loss: 0.0439 - acc: 0.8742 - val_loss: 0.0444 - val_acc: 0.8721\n",
            "Epoch 7/20\n",
            "88/88 [==============================] - 16s 186ms/step - loss: 0.0435 - acc: 0.8783 - val_loss: 0.0442 - val_acc: 0.8743\n",
            "Epoch 8/20\n",
            "88/88 [==============================] - 16s 186ms/step - loss: 0.0435 - acc: 0.8794 - val_loss: 0.0439 - val_acc: 0.8764\n",
            "Epoch 9/20\n",
            "88/88 [==============================] - 16s 187ms/step - loss: 0.0436 - acc: 0.8769 - val_loss: 0.0440 - val_acc: 0.8771\n",
            "Epoch 10/20\n",
            "88/88 [==============================] - 17s 188ms/step - loss: 0.0438 - acc: 0.8754 - val_loss: 0.0441 - val_acc: 0.8757\n",
            "Epoch 11/20\n",
            "88/88 [==============================] - 17s 188ms/step - loss: 0.0436 - acc: 0.8776 - val_loss: 0.0440 - val_acc: 0.8764\n",
            "Epoch 12/20\n",
            "88/88 [==============================] - 17s 188ms/step - loss: 0.0440 - acc: 0.8729 - val_loss: 0.0440 - val_acc: 0.8779\n",
            "Epoch 13/20\n",
            "88/88 [==============================] - 17s 188ms/step - loss: 0.0437 - acc: 0.8754 - val_loss: 0.0439 - val_acc: 0.8779\n",
            "Epoch 14/20\n",
            "88/88 [==============================] - 17s 188ms/step - loss: 0.0439 - acc: 0.8738 - val_loss: 0.0438 - val_acc: 0.8779\n",
            "Epoch 15/20\n",
            "88/88 [==============================] - 17s 189ms/step - loss: 0.0435 - acc: 0.8769 - val_loss: 0.0439 - val_acc: 0.8779\n",
            "Epoch 16/20\n",
            "88/88 [==============================] - 17s 189ms/step - loss: 0.0433 - acc: 0.8794 - val_loss: 0.0441 - val_acc: 0.8750\n",
            "Epoch 17/20\n",
            "88/88 [==============================] - 17s 189ms/step - loss: 0.0438 - acc: 0.8751 - val_loss: 0.0438 - val_acc: 0.8779\n",
            "Epoch 18/20\n",
            "88/88 [==============================] - 17s 189ms/step - loss: 0.0434 - acc: 0.8785 - val_loss: 0.0430 - val_acc: 0.8871\n",
            "Epoch 19/20\n",
            "88/88 [==============================] - 17s 189ms/step - loss: 0.0437 - acc: 0.8758 - val_loss: 0.0436 - val_acc: 0.8800\n",
            "Epoch 20/20\n",
            "88/88 [==============================] - 17s 189ms/step - loss: 0.0434 - acc: 0.8788 - val_loss: 0.0436 - val_acc: 0.8786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eflf3u3938Pl",
        "outputId": "2f12333c-a399-43e3-c525-06f0151e5e7c"
      },
      "source": [
        "Y_val_pred_student = customstudent.predict(x_val)\n",
        "print(f'The CustomStudent model Accuracy on the Validation Set:',accuracy_score(np.argmax(y_val, axis=1), np.argmax(Y_val_pred_student, axis=1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The CustomStudent model Accuracy on the Validation Set: 0.8785714285714286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4CmzFLB4Lew",
        "outputId": "7dc80b1c-12a0-4c21-f3fe-73d991e79115"
      },
      "source": [
        "#Now let's check my Y_test values\n",
        "print(f'My Y_test values are:\\n' ,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My Y_test values are:\n",
            " [[1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXiWzbBA4jgs",
        "outputId": "681fc4c8-2342-4abe-92e5-0738cdba47fd"
      },
      "source": [
        "#Now let's check my predcited values from X_test dataset\n",
        "import timeit\n",
        "\n",
        "start = timeit.default_timer()\n",
        "#Your statements here\n",
        "y_pred_student = customstudent.predict(X_test)\n",
        "print(f'My predicted Y_test values are:\\n' ,y_pred_student)\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "print('\\nTime: ',stop - start,'sec')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My predicted Y_test values are:\n",
            " [[0.73105854 0.26894143 0.5249792  0.4750208 ]\n",
            " [0.26894143 0.73105854 0.4750208  0.5249792 ]\n",
            " [0.73105854 0.26894143 0.5249792  0.4750208 ]\n",
            " ...\n",
            " [0.73105854 0.2689415  0.5249792  0.47502083]\n",
            " [0.31061557 0.68938446 0.4800795  0.5199205 ]\n",
            " [0.73105854 0.26894143 0.5249792  0.4750208 ]]\n",
            "\n",
            "Time:  2.5788797919994977 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvQZH84Z4p9D",
        "outputId": "42d7d3fe-d053-4cb6-c555-fdc58c702016"
      },
      "source": [
        "start = timeit.default_timer()\n",
        "#Your statements here\n",
        "\n",
        "#Now let's check the accuracy between the original & predicted (Y_test , y_pred)\n",
        "print(f'My accuracy on Custom Student model on the Test set is:',accuracy_score(np.argmax(Y_test, axis=1), np.argmax(y_pred_student, axis=1)))\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "print('\\nTime: ',stop - start,'sec')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My accuracy on Custom Student model on the Test set is: 0.9173333333333333\n",
            "\n",
            "Time:  0.0009702650004328461 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZQKmsH7ydM3",
        "outputId": "7f734761-fa65-494c-8109-a2c44756ae65"
      },
      "source": [
        "# Classification_report\n",
        "print(f'Classification Report of Resnet50:\\n',classification_report(np.argmax(Y_test, axis=1), np.argmax(y_pred_student, axis=1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report of Resnet50:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.97      0.92      1500\n",
            "           1       0.96      0.87      0.91      1500\n",
            "\n",
            "    accuracy                           0.92      3000\n",
            "   macro avg       0.92      0.92      0.92      3000\n",
            "weighted avg       0.92      0.92      0.92      3000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKBaOwEJydE1"
      },
      "source": [
        "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from numpy import interp\n",
        "from itertools import cycle\n",
        "\n",
        "num_of_classes = y_train.shape[1]\n",
        "print(f'Auc Curve on Validation:\\n')\n",
        "\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(num_of_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(Y_test_new[:, i], Y_val_pred_student[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "# fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_test_new.ravel(), Y_val_pred_student.ravel())\n",
        "# roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "\n",
        "lw = 3\n",
        "# Plot all ROC curves\n",
        "\n",
        "colors = cycle(['blue', 'orange', 'cornflowerblue'])\n",
        "for i, color in zip(range(num_of_classes), colors):\n",
        "    plt.plot(fpr[i],tpr[i], color=color, lw=lw,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjoxO7sSyrJN"
      },
      "source": [
        "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from numpy import interp\n",
        "from itertools import cycle\n",
        "\n",
        "num_of_classes = y_train.shape[1]\n",
        "print(f'Auc Curve on Test set:\\n')\n",
        "\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(num_of_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(Y_test[:, i], y_pred_student[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "# fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_test.ravel(), y_pred_student.ravel())\n",
        "# roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "\n",
        "lw = 3\n",
        "# Plot all ROC curves\n",
        "\n",
        "colors = cycle(['blue', 'orange', 'cornflowerblue'])\n",
        "for i, color in zip(range(num_of_classes), colors):\n",
        "    plt.plot(fpr[i],tpr[i], color=color, lw=lw,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHcgXahESLKc"
      },
      "source": [
        "-----"
      ]
    }
  ]
}