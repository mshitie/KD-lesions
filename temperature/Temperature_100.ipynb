{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Temperature_100.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mshitie/MS_KD/blob/main/temperature/Temperature_100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yWZxxhrsZiO",
        "outputId": "3ed56336-4f70-4481-c73c-113eb20719d4"
      },
      "source": [
        "\n",
        "!pip install rarfile\n",
        "\n",
        "from google.colab import drive\n",
        "import rarfile\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the .rar file in Google Drive\n",
        "rar_path = '/content/drive/MyDrive/computer_vision/main_data_croped.rar'\n",
        "\n",
        "# Destination folder to extract the contents\n",
        "destination_folder = '/content'\n",
        "\n",
        "# Create the destination folder if it doesn't exist\n",
        "if not os.path.exists(destination_folder):\n",
        "    os.makedirs(destination_folder)\n",
        "\n",
        "# Extract the .rar file\n",
        "with rarfile.RarFile(rar_path, 'r') as rar_ref:\n",
        "    rar_ref.extractall(destination_folder)\n",
        "\n",
        "print(\"Extraction completed.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import shutil\n",
        "\n",
        "def partition_images(directory, csv_file, output_folder):\n",
        "    image_files = []\n",
        "    folder_counts = {}  # Dictionary to store the count of images moved to each folder\n",
        "\n",
        "    # Read the CSV file\n",
        "    with open(csv_file, 'r') as file:\n",
        "        reader = csv.reader(file)\n",
        "        header = next(reader, None)  # Skip the header row if it exists\n",
        "\n",
        "        # Iterate over the rows in the CSV file\n",
        "        for row in reader:\n",
        "            image_file = row[0]  # Assuming the image file names are in the first column\n",
        "            label = row[1]  # Assuming the labels are in the second column\n",
        "            image_files.append((image_file, label))\n",
        "\n",
        "    # Create directories for each label\n",
        "    labels = set(label for _, label in image_files)\n",
        "    for label in labels:\n",
        "        label_dir = os.path.join(output_folder, label)\n",
        "        os.makedirs(label_dir, exist_ok=True)\n",
        "        folder_counts[label] = 0  # Initialize the count to 0\n",
        "\n",
        "    # Move the image files to separate label directories\n",
        "    for image_file, label in image_files:\n",
        "        source_path = os.path.join(directory, image_file + \".jpg\")  # Assuming the file extension is '.jpg'\n",
        "        destination_path = os.path.join(output_folder, label, image_file + \".jpg\")\n",
        "\n",
        "        if os.path.exists(source_path):\n",
        "            print(f\"Moving {source_path} to {destination_path}\")\n",
        "            shutil.move(source_path, destination_path)\n",
        "            folder_counts[label] += 1  # Increment the count for the corresponding folder\n",
        "\n",
        "        else:\n",
        "            print(f\"File not found: {source_path}\")\n",
        "\n",
        "    # Print the counts for each folder\n",
        "    print(\"\\nNumber of images moved in each folder:\")\n",
        "    for label, count in folder_counts.items():\n",
        "        print(f\"{label}: {count}\")\n",
        "\n",
        "# Directory path where the images and CSV file are located\n",
        "directory_path = '/content/main_data_croped/'\n",
        "csv_file_path = '/content/drive/MyDrive/computer_vision/tfti2.csv'\n",
        "output_folder = \"/content/main_data_croped2/\"\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Call the function to partition the images based on the labels\n",
        "partition_images(directory_path, csv_file_path, output_folder)"
      ],
      "metadata": {
        "id": "51dWADmWa3B2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2c0GEuMtO4c"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import scipy\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn')\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import auc, roc_curve\n",
        "from tqdm import tqdm\n",
        "\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPOmCBjttQcT"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "from keras.models import Model\n",
        "from keras.layers import Lambda, concatenate\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import GlobalAveragePooling2D , Conv2D , MaxPooling2D\n",
        "from keras.layers import  Dropout , BatchNormalization , Dense\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from keras.callbacks import Callback , ReduceLROnPlateau , ModelCheckpoint\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "from keras.losses import categorical_crossentropy as logloss\n",
        "from keras.metrics import categorical_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "train_dir = '/content/main_data_croped2'\n",
        "\n",
        "# Load train images\n",
        "tf_train = []\n",
        "for filename in os.listdir(os.path.join(train_dir, 'TF')):\n",
        "    img = Image.open(os.path.join(train_dir, 'TF', filename)).convert('RGB')\n",
        "    img = img.resize((224, 224))  # Resize if necessary\n",
        "    img_array = np.array(img)\n",
        "    tf_train.append(img_array)\n",
        "tf_train = np.array(tf_train)\n",
        "\n",
        "it_train = []\n",
        "for filename in os.listdir(os.path.join(train_dir, 'TI')):\n",
        "    img = Image.open(os.path.join(train_dir, 'TI', filename)).convert('RGB')\n",
        "    img = img.resize((224, 224))  # Resize if necessary\n",
        "    img_array = np.array(img)\n",
        "    it_train.append(img_array)\n",
        "it_train = np.array(it_train)\n",
        "\n",
        "normal_train = []\n",
        "for filename in os.listdir(os.path.join(train_dir, 'normal')):\n",
        "    img = Image.open(os.path.join(train_dir, 'normal', filename)).convert('RGB')\n",
        "    img = img.resize((224, 224))  # Resize if necessary\n",
        "    img_array = np.array(img)\n",
        "    normal_train.append(img_array)\n",
        "normal_train = np.array(normal_train)\n",
        "\n",
        "print('Done Loaded :)')\n",
        "\n",
        "# Shape of our dataset\n",
        "print(f'TF Train:', tf_train.shape)\n",
        "print(f'TI Train:', it_train.shape)\n",
        "print(f'Normal Train:', normal_train.shape)\n",
        "\n",
        "tf_train_label = np.zeros(len(tf_train), dtype=float)\n",
        "it_train_label = np.ones(len(it_train), dtype=float)\n",
        "normal_train_label = np.full(len(normal_train), 2, dtype=float)\n",
        "\n",
        "X_train = np.concatenate((tf_train, it_train, normal_train), axis=0)\n",
        "Y_train = np.concatenate((tf_train_label, it_train_label, normal_train_label), axis=0)\n",
        "\n",
        "s = np.arange(X_train.shape[0])\n",
        "np.random.shuffle(s)\n",
        "X_train = X_train[s]\n",
        "Y_train = Y_train[s]\n",
        "\n",
        "Y_train = to_categorical(Y_train, num_classes=3)\n",
        "\n",
        "print(f'X train shape:', X_train.shape)\n",
        "print(f'Y train shape:', Y_train.shape)\n",
        "\n",
        "# Split the data into training, validation, and testing sets\n",
        "x_train, x_temp, y_train, y_temp = train_test_split(X_train, Y_train, test_size=0.2, random_state=10)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=10)\n",
        "\n",
        "print(f'x train shape:', x_train.shape)\n",
        "print(f'x test shape:', x_test.shape)\n",
        "print(f'x val shape:', x_val.shape)\n",
        "print(f'y train shape:', y_train.shape)\n",
        "print(f'y test shape:', y_test.shape)\n",
        "print(f'y val shape:', y_val.shape)"
      ],
      "metadata": {
        "id": "yBZL5ckha6NJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7mkbYm2ttzr",
        "outputId": "42038e61-8fad-4ec3-8372-589ed8bc8058"
      },
      "source": [
        "# Teacher model with ResNet50\n",
        "def build_model(backbone , lr = 1e-4):\n",
        "  model = Sequential()\n",
        "  model.add(backbone)\n",
        "  model.add(layers.GlobalAveragePooling2D())\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Dense(3 , activation='softmax'))\n",
        "\n",
        "  model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=Adam(learning_rate=lr),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "resnet = ResNet50(\n",
        "    weights = 'imagenet',\n",
        "    include_top = False,\n",
        "    input_shape =(224 , 224 , 3)\n",
        ")\n",
        "#call the model\n",
        "model = build_model(resnet , lr = 1e-4)\n",
        "model.build((None, 224, 224, 3))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 2s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "module_wrapper (ModuleWrappe (None, 7, 7, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 2048)              8192      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 4098      \n",
            "=================================================================\n",
            "Total params: 23,600,002\n",
            "Trainable params: 23,542,786\n",
            "Non-trainable params: 57,216\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1fqZY_ytvj9",
        "outputId": "556fa16c-bcec-4fb0-e99b-2e5137a72406"
      },
      "source": [
        "# Training the teacher model with Resnet50\n",
        "# Train the teacher model as usual\n",
        "epochs = 10\n",
        "batch_size = 64\n",
        "teacher_his = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "88/88 [==============================] - 182s 1s/step - loss: 0.2918 - accuracy: 0.8944 - val_loss: 0.0998 - val_accuracy: 0.9586\n",
            "Epoch 2/10\n",
            "88/88 [==============================] - 122s 1s/step - loss: 0.0825 - accuracy: 0.9676 - val_loss: 0.0818 - val_accuracy: 0.9736\n",
            "Epoch 3/10\n",
            "88/88 [==============================] - 121s 1s/step - loss: 0.0240 - accuracy: 0.9926 - val_loss: 0.0882 - val_accuracy: 0.9693\n",
            "Epoch 4/10\n",
            "88/88 [==============================] - 121s 1s/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 0.1108 - val_accuracy: 0.9736\n",
            "Epoch 5/10\n",
            "88/88 [==============================] - 121s 1s/step - loss: 0.0252 - accuracy: 0.9909 - val_loss: 0.1601 - val_accuracy: 0.9636\n",
            "Epoch 6/10\n",
            "88/88 [==============================] - 121s 1s/step - loss: 0.0220 - accuracy: 0.9916 - val_loss: 0.1472 - val_accuracy: 0.9621\n",
            "Epoch 7/10\n",
            "88/88 [==============================] - 120s 1s/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.1209 - val_accuracy: 0.9736\n",
            "Epoch 8/10\n",
            "88/88 [==============================] - 120s 1s/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.1181 - val_accuracy: 0.9657\n",
            "Epoch 9/10\n",
            "88/88 [==============================] - 120s 1s/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 0.1284 - val_accuracy: 0.9657\n",
            "Epoch 10/10\n",
            "88/88 [==============================] - 120s 1s/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.3533 - val_accuracy: 0.9493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G58ZuNP7t52G",
        "outputId": "a256b4da-3d23-472f-9d8f-87f7b09bbc8c"
      },
      "source": [
        "Y_val_pred = model.predict(x_val)\n",
        "print(f'The Accuracy on the Validation Set:',accuracy_score(np.argmax(y_val, axis=1), np.argmax(Y_val_pred, axis=1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Accuracy on the Validation Set: 0.9492857142857143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ywIDDOzt7gm",
        "outputId": "babc662c-0dd4-44f6-d17d-0a78e4c6d969"
      },
      "source": [
        "#Now let's check my Y_test values\n",
        "print(f'My Y_test values are:\\n' ,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My Y_test values are:\n",
            " [[1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6VEUt6rt86S",
        "outputId": "d2aaba5b-af23-4928-ad6e-0be470d551f6"
      },
      "source": [
        "#Now let's check my predcited values from X_test dataset\n",
        "import timeit\n",
        "\n",
        "start = timeit.default_timer()\n",
        "#Your statements here\n",
        "y_pred = model.predict(X_test)\n",
        "print(f'My predicted Y_test values are:\\n' ,y_pred)\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "print('\\nTime: ',stop - start,'sec')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My predicted Y_test values are:\n",
            " [[9.9999893e-01 1.0158772e-06]\n",
            " [9.9999833e-01 1.6835451e-06]\n",
            " [1.0000000e+00 6.2910126e-09]\n",
            " ...\n",
            " [6.0364165e-13 1.0000000e+00]\n",
            " [6.3864894e-12 1.0000000e+00]\n",
            " [2.7595868e-12 1.0000000e+00]]\n",
            "\n",
            "Time:  20.518026815999974 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FR_AFeNvt-jZ",
        "outputId": "cf56e95c-98d2-4bd7-b913-09a7f0495826"
      },
      "source": [
        "#Now let's check the accuracy between the original & predicted (Y_test , y_pred)\n",
        "print(f'My accuracy on Teacher model with ResNet50 on the Test set is:',accuracy_score(np.argmax(Y_test, axis=1), np.argmax(y_pred, axis=1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My accuracy on Teacher model with ResNet50 on the Test set is: 0.987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53ukzyPguAG_",
        "outputId": "cbb364f6-0b92-4be9-df86-57ed4e90b503"
      },
      "source": [
        "# Print the classification report\n",
        "print(classification_report( np.argmax(Y_test, axis=1), np.argmax(y_pred, axis=1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      1500\n",
            "           1       1.00      0.98      0.99      1500\n",
            "\n",
            "    accuracy                           0.99      3000\n",
            "   macro avg       0.99      0.99      0.99      3000\n",
            "weighted avg       0.99      0.99      0.99      3000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NjmUZkwuBr_",
        "outputId": "ca53c175-e9bb-4525-9c63-b0aa677f299e"
      },
      "source": [
        "# Define the student model\n",
        "# Student model that is stand-alone. We will evaluate its accuracy compared to a teacher trained student model\n",
        "# Hyperparameters\n",
        "input_shape = (224, 224, 3) # Input shape of each image\n",
        "nb_classes = 2\n",
        "\n",
        "\n",
        "student = Sequential()\n",
        "student.add(Conv2D(128, kernel_size=(3, 3),activation='relu', input_shape=input_shape))\n",
        "student.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "student.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "student.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "student.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "student.add(Dropout(0.25)) # For reguralization\n",
        "\n",
        "student.add(layers.Flatten())\n",
        "\n",
        "student.add(layers.Dense(nb_classes))\n",
        "student.add(layers.Activation('softmax')) # Note that we add a normal softmax layer to begin with\n",
        "\n",
        "\n",
        "student.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adadelta',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(student.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_18 (Conv2D)           (None, 222, 222, 128)     3584      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 111, 111, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 109, 109, 64)      73792     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 54, 54, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 52, 52, 32)        18464     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 52, 52, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 86528)             0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 2)                 173058    \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 268,898\n",
            "Trainable params: 268,898\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kVFMjsMuDrT"
      },
      "source": [
        "#Collect the logits from the previous layer output and store it in a different model\n",
        "teacher_WO_Softmax = Model(model.input, model.get_layer('dense').output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JtbWCrzuFh1"
      },
      "source": [
        "# Define a manual softmax function\n",
        "def softmax(x):\n",
        "    return np.exp(x)/(np.exp(x).sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VN7Ct6W-RcQ"
      },
      "source": [
        "# Temperature = 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ryhWcc2uG98",
        "outputId": "da453b28-c25c-4062-bb63-2b4549dfc056"
      },
      "source": [
        "# Prepare the soft targets and the target data for student to be trained upon\n",
        "temp = 100\n",
        "# This model directly gives the logits ( see the teacher_WO_softmax model above)\n",
        "teacher_train_logits = teacher_WO_Softmax.predict(x_train)\n",
        "teacher_test_logits = teacher_WO_Softmax.predict(x_val)\n",
        "\n",
        "# Perform a manual softmax at raised temperature\n",
        "train_logits_T = teacher_train_logits/temp # temp = 100\n",
        "test_logits_T = teacher_test_logits/temp\n",
        "\n",
        "Y_train_soft = softmax(train_logits_T)\n",
        "Y_test_soft = softmax(test_logits_T)\n",
        "\n",
        "# Concatenate\n",
        "Y_train_new = np.concatenate([y_train, Y_train_soft], axis=1)\n",
        "Y_test_new =  np.concatenate([y_val, Y_test_soft], axis =1)\n",
        "\n",
        "#Print the Shape\n",
        "print(train_logits_T.shape)\n",
        "print(test_logits_T.shape)\n",
        "print(Y_train_new.shape)\n",
        "print(Y_test_new.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5596, 2)\n",
            "(1400, 2)\n",
            "(5596, 4)\n",
            "(1400, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVKCmvIouIiM",
        "outputId": "3b35714f-7933-491f-8279-d5f595fcb599"
      },
      "source": [
        "# Prepare the student model that outputs probabilities with and without temperature\n",
        "# Remove the softmax layer from the student network\n",
        "temp = 100\n",
        "student.layers.pop()\n",
        "\n",
        "# Now collect the logits from the last layer\n",
        "# This is going to be a tensor. And hence it needs to pass through a Activation layer\n",
        "logits = student.layers[-1].output\n",
        "probs = layers.Activation('softmax')(logits)\n",
        "\n",
        "\n",
        "# softed probabilities at raised temperature\n",
        "logits_T = Lambda(lambda x: x / temp)(logits)\n",
        "probs_T = layers.Activation('softmax')(logits_T)\n",
        "\n",
        "output = concatenate([probs, probs_T])\n",
        "\n",
        "# This is our new student model\n",
        "student = Model(student.input, output)\n",
        "\n",
        "student.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "conv2d_18_input (InputLayer)    [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 222, 222, 128 3584        conv2d_18_input[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling2D) (None, 111, 111, 128 0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 109, 109, 64) 73792       max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 54, 54, 64)   0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 52, 52, 32)   18464       max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 52, 52, 32)   0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 86528)        0           dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 2)            173058      flatten_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 2)            0           dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, 2)            0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 2)            0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 2)            0           lambda_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 4)            0           activation_19[0][0]              \n",
            "                                                                 activation_20[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 268,898\n",
            "Trainable params: 268,898\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmeUKuePuKNg"
      },
      "source": [
        "# Declare knowledge distillation loss function\n",
        "# This will be a teacher trained student model.\n",
        "# This uses a knowledge distillation loss function\n",
        "\n",
        "# Declare knowledge distillation loss\n",
        "def knowledge_distillation_loss(y_true, y_pred, alpha):\n",
        "\n",
        "    # Extract the one-hot encoded values and the softs separately so that we can create two objective functions\n",
        "    y_true, y_true_softs = y_true[: , :nb_classes], y_true[: , nb_classes:]\n",
        "\n",
        "    y_pred, y_pred_softs = y_pred[: , :nb_classes], y_pred[: , nb_classes:]\n",
        "\n",
        "    loss = alpha*logloss(y_true,y_pred) + (1-alpha)*logloss(y_true_softs, y_pred_softs)\n",
        "\n",
        "    return loss\n",
        "\n",
        "# For testing use regular output probabilities - without temperature\n",
        "def acc(y_true, y_pred):\n",
        "    y_true = y_true[:, :nb_classes]\n",
        "    y_pred = y_pred[:, :nb_classes]\n",
        "    return categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "student.compile(\n",
        "    #optimizer=optimizers.SGD(lr=1e-1, momentum=0.9, nesterov=True),\n",
        "    optimizer='adadelta',\n",
        "    loss=lambda y_true, y_pred: knowledge_distillation_loss(y_true, y_pred, 0.1),\n",
        "    #loss='categorical_crossentropy',\n",
        "    metrics=[acc] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmtmEPyIuL1-",
        "outputId": "5479567a-e95d-43d9-efcb-9706b1b23bc0"
      },
      "source": [
        "# Train the student model\n",
        "epochs = 20\n",
        "batch_size = 64\n",
        "student_his = student.fit(x_train, Y_train_new,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_val, Y_test_new))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "88/88 [==============================] - 39s 424ms/step - loss: 0.0800 - acc: 0.5132 - val_loss: 0.0806 - val_acc: 0.5107\n",
            "Epoch 2/20\n",
            "88/88 [==============================] - 37s 417ms/step - loss: 0.0784 - acc: 0.5264 - val_loss: 0.0720 - val_acc: 0.5857\n",
            "Epoch 3/20\n",
            "88/88 [==============================] - 37s 417ms/step - loss: 0.0749 - acc: 0.5564 - val_loss: 0.0742 - val_acc: 0.5700\n",
            "Epoch 4/20\n",
            "88/88 [==============================] - 37s 417ms/step - loss: 0.0746 - acc: 0.5621 - val_loss: 0.0658 - val_acc: 0.6529\n",
            "Epoch 5/20\n",
            "88/88 [==============================] - 37s 418ms/step - loss: 0.0728 - acc: 0.5765 - val_loss: 0.0587 - val_acc: 0.7214\n",
            "Epoch 6/20\n",
            "88/88 [==============================] - 37s 418ms/step - loss: 0.0716 - acc: 0.5908 - val_loss: 0.0578 - val_acc: 0.7357\n",
            "Epoch 7/20\n",
            "88/88 [==============================] - 37s 417ms/step - loss: 0.0694 - acc: 0.6125 - val_loss: 0.0589 - val_acc: 0.7243\n",
            "Epoch 8/20\n",
            "88/88 [==============================] - 37s 417ms/step - loss: 0.0682 - acc: 0.6228 - val_loss: 0.0570 - val_acc: 0.7364\n",
            "Epoch 9/20\n",
            "88/88 [==============================] - 37s 418ms/step - loss: 0.0680 - acc: 0.6288 - val_loss: 0.0619 - val_acc: 0.6950\n",
            "Epoch 10/20\n",
            "88/88 [==============================] - 37s 417ms/step - loss: 0.0658 - acc: 0.6483 - val_loss: 0.0578 - val_acc: 0.7350\n",
            "Epoch 11/20\n",
            "88/88 [==============================] - 37s 418ms/step - loss: 0.0652 - acc: 0.6573 - val_loss: 0.0597 - val_acc: 0.7193\n",
            "Epoch 12/20\n",
            "88/88 [==============================] - 37s 417ms/step - loss: 0.0659 - acc: 0.6493 - val_loss: 0.0546 - val_acc: 0.7686\n",
            "Epoch 13/20\n",
            "88/88 [==============================] - 37s 418ms/step - loss: 0.0649 - acc: 0.6594 - val_loss: 0.0605 - val_acc: 0.7071\n",
            "Epoch 14/20\n",
            "88/88 [==============================] - 37s 417ms/step - loss: 0.0632 - acc: 0.6776 - val_loss: 0.0561 - val_acc: 0.7550\n",
            "Epoch 15/20\n",
            "88/88 [==============================] - 37s 418ms/step - loss: 0.0636 - acc: 0.6744 - val_loss: 0.0542 - val_acc: 0.7707\n",
            "Epoch 16/20\n",
            "88/88 [==============================] - 37s 417ms/step - loss: 0.0620 - acc: 0.6915 - val_loss: 0.0540 - val_acc: 0.7729\n",
            "Epoch 17/20\n",
            "88/88 [==============================] - 37s 418ms/step - loss: 0.0638 - acc: 0.6710 - val_loss: 0.0602 - val_acc: 0.7114\n",
            "Epoch 18/20\n",
            "88/88 [==============================] - 37s 417ms/step - loss: 0.0610 - acc: 0.7015 - val_loss: 0.0530 - val_acc: 0.7807\n",
            "Epoch 19/20\n",
            "88/88 [==============================] - 37s 418ms/step - loss: 0.0617 - acc: 0.6925 - val_loss: 0.0541 - val_acc: 0.7721\n",
            "Epoch 20/20\n",
            "88/88 [==============================] - 37s 417ms/step - loss: 0.0603 - acc: 0.7059 - val_loss: 0.0552 - val_acc: 0.7643\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIbKXx9Xyeqx"
      },
      "source": [
        "#https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
        "# summarize history for accuracy\n",
        "plt.plot(student_his.history['acc'])\n",
        "plt.plot(student_his.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiFMqdacyhUA"
      },
      "source": [
        "#https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
        "# summarize history for accuracy\n",
        "plt.plot(student_his.history['loss'])\n",
        "plt.plot(student_his.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='lower left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wqib9P66uUPs",
        "outputId": "e73d9021-01c7-4dbe-e70c-d25ecb763717"
      },
      "source": [
        "Y_val_pred = student.predict(x_val)\n",
        "print(f'The Accuracy on the Validation Set:',accuracy_score(np.argmax(y_val, axis=1), np.argmax(Y_val_pred, axis=1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Accuracy on the Validation Set: 0.7642857142857142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42YiygwYuVeY",
        "outputId": "d9e3f4f1-58c3-404f-b16f-92bc1e6f613e"
      },
      "source": [
        "#Now let's check my Y_test values\n",
        "print(f'My Y_test values are:\\n' ,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My Y_test values are:\n",
            " [[1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSPvbOaruW84",
        "outputId": "3ad285b9-4b49-4a3e-b633-3d7619cadd3d"
      },
      "source": [
        "#Now let's check my predcited values from X_test dataset\n",
        "import timeit\n",
        "\n",
        "start = timeit.default_timer()\n",
        "#Your statements here\n",
        "y_pred = student.predict(X_test)\n",
        "print(f'My predicted Y_test values are:\\n' ,y_pred)\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "print('\\nTime: ',stop - start,'sec')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My predicted Y_test values are:\n",
            " [[0.73105854 0.26894143 0.5025     0.49750003]\n",
            " [0.73105854 0.2689415  0.5025     0.49750003]\n",
            " [0.7310583  0.2689417  0.5025     0.49750003]\n",
            " ...\n",
            " [0.73105854 0.26894143 0.5025     0.49750003]\n",
            " [0.73105854 0.26894143 0.5025     0.49750003]\n",
            " [0.26894143 0.73105854 0.49750003 0.5025    ]]\n",
            "\n",
            "Time:  10.274113266999848 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1kDQ4Z4uY1w",
        "outputId": "34fa4775-c5f1-4a41-a0cb-22f385d61abe"
      },
      "source": [
        "#Now let's check the accuracy between the original & predicted (Y_test , y_pred)\n",
        "print(f'My accuracy on Teacher model with ResNet50 on the Test set is:',accuracy_score(np.argmax(Y_test, axis=1), np.argmax(y_pred, axis=1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My accuracy on Teacher model with ResNet50 on the Test set is: 0.7723333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0svcudKOuay8",
        "outputId": "fc1732de-d52a-493f-ec50-bc88e050024b"
      },
      "source": [
        "# Print the classification report\n",
        "print(classification_report( np.argmax(Y_test, axis=1), np.argmax(y_pred, axis=1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      1.00      0.81      1500\n",
            "           1       0.99      0.55      0.71      1500\n",
            "\n",
            "    accuracy                           0.77      3000\n",
            "   macro avg       0.84      0.77      0.76      3000\n",
            "weighted avg       0.84      0.77      0.76      3000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlV8eEvUyWyT"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# roc curve for models\n",
        "fpr1, tpr1, thresh1 = roc_curve(np.argmax(Y_test, axis=1), np.argmax(y_pred, axis=1),pos_label=1)\n",
        "\n",
        "# roc curve for\n",
        "random_probs = [0 for i in range(len(np.argmax(Y_test, axis=1)))]\n",
        "p_fpr, p_tpr, _ = roc_curve(np.argmax(Y_test, axis=1), random_probs, pos_label=1)\n",
        "\n",
        "# auc scores\n",
        "from sklearn.metrics import roc_auc_score\n",
        "auc_score1 = roc_auc_score(np.argmax(Y_test, axis=1), np.argmax(y_pred, axis=1))\n",
        "print(auc_score1)\n",
        "\n",
        "\n",
        "# matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "# plot roc curves\n",
        "plt.plot(fpr1, tpr1, linestyle='--',color='orange')\n",
        "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
        "# title\n",
        "plt.title('ROC curve')\n",
        "# x label\n",
        "plt.xlabel('\\nFalse Positive Rate')\n",
        "# y label\n",
        "plt.ylabel('\\nTrue Positive rate')\n",
        "\n",
        "plt.legend(loc='best')\n",
        "plt.savefig('ROC',dpi=300)\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}